{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing \n",
    "\n",
    "This code will read in data from the experiments carried out and extract the important information which is fed to the LSTM cell. \n",
    "\n",
    "The very first step would be to extract the start and end indices of the data for each subject using the following function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_end_extractor (data, prior_seconds): \n",
    "    # data is the dataset; prior_seconds is the number of seconds to be considered in the data\n",
    "    # before the warning is given \n",
    "\n",
    "    warningStartIndices= data[data['warning'].notnull()].index # Extracts the warning indices\n",
    "    startindex = np.zeros(shape=(len(warningStartIndices),1))\n",
    "    endindex = np.zeros(shape=(len(warningStartIndices),1))\n",
    "    ei = 0\n",
    "    si = 0\n",
    "    \n",
    "    for i in warningStartIndices:\n",
    "        k = 0\n",
    "        \n",
    "        # The following WHILE loop identifies the startindex for relevant data\n",
    "        while ((data['time(s)'][i] - data['time(s)'][i + k]) < (prior_seconds + 0.001) ):\n",
    "            k -= 1\n",
    "        j = 0\n",
    "        \n",
    "        # The following WHILE loop identifies the endindex for relevant data\n",
    "        while (abs(data['steering angle(deg)'][i] - data['steering angle(deg)'][i+j]) < 2)\\\n",
    "        & (data['padel1'][i+j] <= 32511):\n",
    "            j += 1\n",
    "        \n",
    "        startindex[si] = i + k \n",
    "        si += 1\n",
    "        endindex[ei] = i + j\n",
    "        ei += 1\n",
    "        \n",
    "        startindex = startindex.astype(int)\n",
    "        endindex = endindex.astype(int)\n",
    "    dataSplitVector = endindex - startindex\n",
    "    \n",
    "    #print(startindex, endindex, dataSplitVector,warningStartIndices)   \n",
    "    return startindex, endindex, dataSplitVector,warningStartIndices\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the relevant start and end points for each event we can extract other information such as the collision/no-collision output for the events as done in the function below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_extractor (data, startindex, endindex):\n",
    "    # This function takes as its input the unlceaned raw data and the event start and end \n",
    "    # indices. It outputs an array which tells whether colision took place for every event\n",
    "    # for a given subject\n",
    "    \n",
    "    output = np.zeros(shape = (endindex.size))\n",
    "    \n",
    "    for i in range(endindex.size):\n",
    "        if i != (endindex.size -1): # The last index will not have a start index for the next event \n",
    "            if data['crash'].values[endindex[i]][0] != data['crash'].values[startindex[i+1]]:\n",
    "            # Comparing the values in the crash column for end index of event i to start index of \n",
    "            # event i+1. If these values are different then it suggests there was a collision.\n",
    "            # This means the output will be 1 = collision\n",
    "                output[i] = 1\n",
    "            else:\n",
    "                output[i] = 0\n",
    "        else:\n",
    "            if data['crash'].values[endindex[i]][0] != data['crash'].values[-1]:\n",
    "                output[i] = 1\n",
    "            else:\n",
    "                output[i] = 0\n",
    "                \n",
    "    output = pd.DataFrame(output)\n",
    "            \n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The following set of functions will now start modeling the lead vehicle movement in terms of lead vehicle velocity and position:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_lenghts (event_sequence, incident_distance, max_distance):\n",
    "    # This function will take as its input the event_sequence which is taken from the 'event'\n",
    "    # column of the 'SUMMARY' sheet. The incident_distance and max_distance arguments are the \n",
    "    # parameters defined in the experiment setup. The former is the distance at which the \n",
    "    # incident takes place and the latter is the max distance over which an event occurs. This\n",
    "    # function returns the distance from the very start at which every scenario begins and ends.\n",
    "    \n",
    "\n",
    "    incident_startpt = np.zeros(shape= (16,1))\n",
    "    incident_endpt = np.zeros(shape= (16,1))\n",
    "    \n",
    "    # dist_counter keeps track of the distance covered\n",
    "    dist_counter = 0   \n",
    "    \n",
    "    for i in range (0,16): \n",
    "        # incident_startpt is the distance where the lead vehicle starts decelerating\n",
    "        incident_startpt[i] = dist_counter + incident_distance[int(event_sequence[i])-1]\n",
    "        # incident_endpt is the distance where the scenario ends\n",
    "        incident_endpt[i] = dist_counter + max_distance[int(event_sequence[i])-1]\n",
    "        dist_counter += max_distance[int(event_sequence[i])-1]\n",
    "    \n",
    "    return incident_startpt, incident_endpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lead_vehicle_movement(data,event_sequence,scen_data,incident_startpt,incident_endpt,warningStartIndices):\n",
    "    # This function takes as its input the raw data which has been modified to include the \n",
    "    # columns for lead vehicle velocity and distance. It also takes the sequence of events \n",
    "    # from the summary sheet, the summary data along with incident_startpt and incident_endpt \n",
    "    # as its inputs. \n",
    "    \n",
    "    # dp_counter will keep incrimenting to go to the next data point - dp stands \n",
    "    # for data point here\n",
    "    dp_counter = 0\n",
    "\n",
    "    # We will check every scenario and match it to the events 1 through 8\n",
    "    for i in range (0,16):\n",
    "        # The following condition allows events only from 1,2,3,4,7 and 8 as they have similar\n",
    "        # lead vehicle movement\n",
    "        if (int((event_sequence[i]) != 5) & (int(event_sequence[i]) != 6)):\n",
    "            \n",
    "            # v_finder keeps track of when the deceleration of lead vehicle starts\n",
    "            v_finder = 0\n",
    "            \n",
    "            # This loop will acertain that all the data points of this event are  \n",
    "            while (data['dis(feet)'][dp_counter] <= incident_endpt[i]):\n",
    "                #print(dp_counter)\n",
    "                # The lead vehicle mimics the movement of the subject vehicle and is always \n",
    "                # 100 ft ahead of it before the latter reaches the designated distance for\n",
    "                # the deceleration to begin. This is already decided in the experiment.\n",
    "                if data['dis(feet)'][dp_counter] < (incident_startpt[i]-100):\n",
    "                    data['lvv'][dp_counter] = data['long v(m/s)'][dp_counter]\n",
    "                    data['lvd'][dp_counter] = data['dis(feet)'][dp_counter] + 100\n",
    "                    \n",
    "                # Once the event starts the lead vehicle decelerates to a stop in 2 seconds    \n",
    "                elif data['dis(feet)'][dp_counter] <= incident_endpt[i]:\n",
    "                    \n",
    "                    if v_finder == 0: \n",
    "                    # This condition ensures that the following calculations take place only\n",
    "                    # once per event\n",
    "                        v_finder += 1\n",
    "                        init_v = data['long v(m/s)'][dp_counter]       # decc start velocity\n",
    "                        init_t = data['time(s)'][dp_counter]           # decc start time\n",
    "                        init_d = data['dis(feet)'][dp_counter] + 100   # decc start position\n",
    "                        t = 2                                          # time to deccelerate \n",
    "                        a = -init_v/t                                  # decceleration\n",
    "\n",
    "                    # Time elapsed between decceleration start and the current data point\n",
    "                    T = data['time(s)'][dp_counter]-init_t               \n",
    "                         \n",
    "                    # Velocity will keep reducing until it is 0 after which it will stay 0 \n",
    "                    data['lvv'][dp_counter] = max(0, init_v + a*T)\n",
    "                    \n",
    "                    # If the velocity is zero then the distance will stop changing\n",
    "                    if data['lvv'][dp_counter] == 0:\n",
    "                        data['lvd'][dp_counter] = data['lvd'][dp_counter-1]\n",
    "                    else:\n",
    "                        data['lvd'][dp_counter] =  init_d + init_v*T + 0.5*a*T*T\n",
    "\n",
    "                dp_counter += 1\n",
    "                if dp_counter == len(data):\n",
    "                    break\n",
    "\n",
    "        # The following condition will allow only event 6 with warning lead time of 2.5s\n",
    "        elif ((int(event_sequence[i]) == 6) & (scen_data['lead time'][i] == 2.5)) :\n",
    "            \n",
    "            # v_finder will keep track of the decceleration start\n",
    "            v_finder = 0\n",
    "            \n",
    "            while data['dis(feet)'][dp_counter] <= incident_endpt[i]:\n",
    "                \n",
    "                # The lead vehicle will be 50 ft ahead of the subject before the incident \n",
    "                # starts and its velocity will be the same as that of the subject vehicle\n",
    "                if data['dis(feet)'][dp_counter] < (incident_startpt[i] - 50):\n",
    "                    data['lvv'][dp_counter] = data['long v(m/s)'][dp_counter]\n",
    "                    data['lvd'][dp_counter] = data['dis(feet)'][dp_counter] + 50\n",
    "                \n",
    "                # When the lead vehicle starts to deccelerate it will do so in 1s.\n",
    "                elif data['dis(feet)'][dp_counter] <= incident_endpt[i]:\n",
    "                    if v_finder == 0:\n",
    "                        v_finder += 1\n",
    "                        init_v = data['long v(m/s)'][dp_counter]     # decc start velocity\n",
    "                        init_t = data['time(s)'][dp_counter]         # decc start time\n",
    "                        init_d = data['dis(feet)'][dp_counter] + 50  # decc start position\n",
    "                        t = 1                                         # time for decceleration\n",
    "                        a = -init_v/t                                 # decceleration\n",
    "\n",
    "                    # Time elapsed between decceleration start and the current data point\n",
    "                    T = data['time(s)'][dp_counter]-init_t               \n",
    "                         \n",
    "                    # Velocity will keep reducing until it is 0 after which it will stay 0 \n",
    "                    data['lvv'][dp_counter] = max(0, init_v + a*T)\n",
    "                    \n",
    "                    # If the velocity is zero then the distance will stop changing\n",
    "                    if data['lvv'][dp_counter] == 0:\n",
    "                        data['lvd'][dp_counter] = data['lvd'][dp_counter-1]\n",
    "                    else:\n",
    "                        data['lvd'][dp_counter] =  init_d + init_v*T + 0.5*a*T*T\n",
    "\n",
    "                dp_counter += 1\n",
    "                if dp_counter == len(data):\n",
    "                    break\n",
    "                \n",
    "        # The following condition will allow only event 6 with warning lead time of 4.5s\n",
    "        elif ((int(event_sequence[i]) == 6) & (scen_data['lead time'][i] == 4.5)) :\n",
    "            \n",
    "            v_finder = 0\n",
    "            while data['dis(feet)'][dp_counter] <= incident_endpt[i]:\n",
    "                \n",
    "                # The lead vehicle will be 90 ft ahead of the subject before the incident \n",
    "                # starts and its velocity will be the same as that of the subject vehicle\n",
    "                if data['dis(feet)'][dp_counter] < (incident_startpt[i] - 90):\n",
    "                    data['lvv'][dp_counter] = data['long v(m/s)'][dp_counter]\n",
    "                    data['lvd'][dp_counter] = data['dis(feet)'][dp_counter] + 90\n",
    "                \n",
    "                # When the lead vehicle starts to deccelerate it will do so in 1s.\n",
    "                elif data['dis(feet)'][dp_counter] <= incident_endpt[i]:\n",
    "                    if v_finder == 0:\n",
    "                        v_finder += 1\n",
    "                        init_v = data['long v(m/s)'][dp_counter]     # decc start velocity\n",
    "                        init_t = data['time(s)'][dp_counter]         # decc start time\n",
    "                        init_d = data['dis(feet)'][dp_counter] + 90  # decc start position \n",
    "                        t = 1                                        # time for decceleration \n",
    "                        a = -init_v/t                                # decceleration\n",
    "\n",
    "                    # Time elapsed between decceleration start and the current data point\n",
    "                    T = data['time(s)'][dp_counter]-init_t               \n",
    "                         \n",
    "                    # Velocity will keep reducing until it is 0 after which it will stay 0 \n",
    "                    data['lvv'][dp_counter] = max(0, init_v + a*T)\n",
    "                    \n",
    "                    # If the velocity is zero then the distance will stop changing\n",
    "                    if data['lvv'][dp_counter] == 0:\n",
    "                        data['lvd'][dp_counter] = data['lvd'][dp_counter-1]\n",
    "                    else:\n",
    "                        data['lvd'][dp_counter] =  init_d + init_v*T + 0.5*a*T*T\n",
    "\n",
    "                dp_counter += 1\n",
    "                if dp_counter == len(data):\n",
    "                    break\n",
    "\n",
    "        # The following condition will allow event 5 with warning lead time of 2.5s       \n",
    "        elif ((int(event_sequence[i]) == 5) & (scen_data['lead time'][i] == 2.5)) :\n",
    "            \n",
    "            WT = data['time(s)'][warningStartIndices[i]]            # Waring time instant\n",
    "            u = data['long v(m/s)'][warningStartIndices[i]] + 66    # Relative velocity of lead vehicle\n",
    "            import math\n",
    "            v = -((134.36)**2 + 2*(-66)*179)\n",
    "            v = math.sqrt(v)                                        # Relative velocity when distance is covered \n",
    "            t = (u-v)/66                                            # Time to deccelerate to that velocity\n",
    "            T = 2.5 - t                                             # Time before WT that decc starts\n",
    "            decc_start_time = WT + T                                # Time when decc starts\n",
    "            \n",
    "            while data['dis(feet)'][dp_counter] <= incident_endpt[i]:\n",
    "                #print(dp_counter, decc_start_time, WT, u, v , t , T)\n",
    "                # Before decc_start_time the speed of the oncoming vehicle will be constant at\n",
    "                # 66 ft/s and its distance will be calculated accordingly\n",
    "                if data['time(s)'][dp_counter] <= decc_start_time:\n",
    "                    data['lvv'][dp_counter] = 66\n",
    "                    data['lvd'][dp_counter] = (decc_start_time - data['time(s)'][dp_counter])\\\n",
    "                    *66 + 179 + data['dis(feet)'][dp_counter]\n",
    "                    \n",
    "                elif data['dis(feet)'][dp_counter] <= incident_endpt[i]:\n",
    "                    data['lvv'][dp_counter] = max(0, (data['lvv'][dp_counter-1] + (data['time(s)'][dp_counter]\\\n",
    "                                                                             - data['time(s)'][dp_counter- 1])*(-66)))\n",
    "                    if data['lvv'][dp_counter] == 0:\n",
    "                        data['lvd'][dp_counter] = data['lvd'][dp_counter-1]\n",
    "                    else:\n",
    "                        time = (data['time(s)'][dp_counter] - data['time(s)'][dp_counter-1])\n",
    "                        init_v = data['lvv'][dp_counter - 1]\n",
    "                        data['lvd'][dp_counter] = data['lvd'][dp_counter-1] - init_v*time - (0.5*(-66)*(time**2))\n",
    "                \n",
    "                dp_counter += 1\n",
    "                if dp_counter == len(data):\n",
    "                    break\n",
    "                \n",
    "                \n",
    "        # The following condition will allow event 5 with warning lead time of 4.5s       \n",
    "        elif ((int(event_sequence[i]) == 5) & (scen_data['lead time'][i] == 4.5)) :\n",
    "            \n",
    "            WT = data['time(s)'][warningStartIndices[i]]            # Waring time instant\n",
    "            u = data['long v(m/s)'][warningStartIndices[i]] + 66    # Relative velocity of lead vehicle\n",
    "            import math\n",
    "            v = -((134.36)**2 + 2*(-66)*179)\n",
    "            v = math.sqrt(v)                                        # Relative velocity when distance is covered \n",
    "            t = (u-v)/66                                            # Time to deccelerate to that velocity\n",
    "            T = 4.5 - t                                             # Time before WT that decc starts\n",
    "            decc_start_time = WT + T                                # Time when decc starts\n",
    "            \n",
    "            while data['dis(feet)'][dp_counter] <= incident_endpt[i]:\n",
    "                \n",
    "                # Before decc_start_time the speed of the oncoming vehicle will be constant at\n",
    "                # 66 ft/s and its distance will be calculated accordingly\n",
    "                if data['time(s)'][dp_counter] <= decc_start_time:\n",
    "                    data['lvv'][dp_counter] = 66\n",
    "                    data['lvd'][dp_counter] = (decc_start_time - data['time(s)'][dp_counter])\\\n",
    "                    *66 + 311 + data['dis(feet)'][dp_counter]\n",
    "                    \n",
    "                elif data['dis(feet)'][dp_counter] <= incident_endpt[i]:\n",
    "                    data['lvv'][dp_counter] = max(0, (data['lvv'][dp_counter-1] + (data['time(s)'][dp_counter]\\\n",
    "                                                                             - data['time(s)'][dp_counter- 1])*(-66)))\n",
    "                    if data['lvv'][dp_counter] == 0:\n",
    "                        data['lvd'][dp_counter] = data['lvd'][dp_counter-1]\n",
    "                    else:\n",
    "                        time = (data['time(s)'][dp_counter] - data['time(s)'][dp_counter-1])\n",
    "                        init_v = data['lvv'][dp_counter - 1]\n",
    "                        data['lvd'][dp_counter] = data['lvd'][dp_counter-1] - init_v*time - (0.5*(-66)*(time**2))\n",
    "                \n",
    "                dp_counter += 1\n",
    "                if dp_counter == len(data):\n",
    "                    break\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a data frame which also has the lead vehicle movement in it we will work on extracting data relevent to us and store it in a new data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function modifies the dataframe to include the columns lvv and lvd and initialise them to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_modifier_1 (data):\n",
    "    data['lvv'] = 0\n",
    "    data['lvd'] = 0\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The follwoing function will modify the dataframe to rename the columns and and drop the unnecessary ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_modifier_2 (data, startindex, endindex, dataSplitVector):\n",
    "    \n",
    "    # Write the code here\n",
    "    data2 = np.zeros(shape=(sum(dataSplitVector).astype(int)[0],data.shape[1]))\n",
    "    j = 0\n",
    "    for i in range (endindex.size):\n",
    "        for k in range (startindex[i][0], endindex[i][0]):\n",
    "            data2[j] = data.values[k]\n",
    "            j += 1\n",
    "        print(\"The no. of time stamps for event {} are {}\".format(i+1,(endindex[i][0] - startindex[i][0])))\n",
    "    featureList = data.columns[0:16]\n",
    "    #print(featureList)\n",
    "    data3 = pd.DataFrame(data = data2)\n",
    "    data3.columns = featureList\n",
    "    #data3\n",
    "    \n",
    "    return data3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main function is as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function1(data, scen_data):\n",
    "\n",
    "    # Step 2: Dropping unnecessary columns\n",
    "    data = data.drop(data.columns[14:],axis = 1)\n",
    "\n",
    "    # Step 3: Extracting start and end indices of the data which are relevnt to our model training\n",
    "    startindex, endindex, dataSplitVector, warningStartIndices = start_end_extractor(data, prior_seconds = 1)\n",
    "\n",
    "    # Step 4: Extracting the output of the events \n",
    "    output = output_extractor(data,startindex,endindex)\n",
    "\n",
    "    # Step 5: Modifying the initial dataset to add lead vehicle movement columns\n",
    "    data = df_modifier_1(data)\n",
    "\n",
    "    # Step 6: Extract the event sequence data from the Summary sheet\n",
    "    #scen_data = pd.read_excel('/Users/RSM/Downloads/DataToBeCleaned.xlsx', sheet_name = 'SUMMARY')\n",
    "    #scen_data =scen_data.drop([16,17])  \n",
    "    event_sequence = scen_data['event'].values\n",
    "\n",
    "    # Step 7: Extract the incidence start point and end point to model the movement\n",
    "    incident_distance = [2880,3880,4880,3880,0,1100,2400,880]\n",
    "    max_distance = [4000,5000,6000,5000,3000,2000,3000,2000]\n",
    "    incident_startpt, incident_endpt = event_lenghts(event_sequence, incident_distance, max_distance)\n",
    "    incident_endpt[-1] = data['dis(feet)'][len(data['dis(feet)'])-1]\n",
    "\n",
    "    # Step 8: Model the lead vehicle movement and update the 'lvv' and 'lvd' columns\n",
    "    data2 = lead_vehicle_movement(data,event_sequence,scen_data,incident_startpt,incident_endpt, warningStartIndices)\n",
    "\n",
    "    # Step 9: Extract the relevant portion of the data \n",
    "    data_rel = df_modifier_2(data2, startindex, endindex, dataSplitVector)\n",
    "    \n",
    "    return data_rel, dataSplitVector, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:131: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:129: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:192: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:196: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:202: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no. of time stamps for event 1 are 19\n",
      "The no. of time stamps for event 2 are 18\n",
      "The no. of time stamps for event 3 are 14\n",
      "The no. of time stamps for event 4 are 19\n",
      "The no. of time stamps for event 5 are 31\n",
      "The no. of time stamps for event 6 are 31\n",
      "The no. of time stamps for event 7 are 16\n",
      "The no. of time stamps for event 8 are 50\n",
      "The no. of time stamps for event 9 are 19\n",
      "The no. of time stamps for event 10 are 17\n",
      "The no. of time stamps for event 11 are 16\n",
      "The no. of time stamps for event 12 are 17\n",
      "The no. of time stamps for event 13 are 15\n",
      "The no. of time stamps for event 14 are 16\n",
      "The no. of time stamps for event 15 are 17\n",
      "The no. of time stamps for event 16 are 15\n",
      "Data for Subject 1 has been cleaned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:154: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:156: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:162: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:93: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no. of time stamps for event 1 are 22\n",
      "The no. of time stamps for event 2 are 18\n",
      "The no. of time stamps for event 3 are 16\n",
      "The no. of time stamps for event 4 are 19\n",
      "The no. of time stamps for event 5 are 18\n",
      "The no. of time stamps for event 6 are 21\n",
      "The no. of time stamps for event 7 are 17\n",
      "The no. of time stamps for event 8 are 16\n",
      "The no. of time stamps for event 9 are 16\n",
      "The no. of time stamps for event 10 are 16\n",
      "The no. of time stamps for event 11 are 11\n",
      "The no. of time stamps for event 12 are 13\n",
      "The no. of time stamps for event 13 are 16\n",
      "The no. of time stamps for event 14 are 15\n",
      "The no. of time stamps for event 15 are 16\n",
      "The no. of time stamps for event 16 are 16\n",
      "Data for Subject 2 has been cleaned.\n",
      "The no. of time stamps for event 1 are 17\n",
      "The no. of time stamps for event 2 are 17\n",
      "The no. of time stamps for event 3 are 14\n",
      "The no. of time stamps for event 4 are 17\n",
      "The no. of time stamps for event 5 are 15\n",
      "The no. of time stamps for event 6 are 16\n",
      "The no. of time stamps for event 7 are 20\n",
      "The no. of time stamps for event 8 are 16\n",
      "The no. of time stamps for event 9 are 17\n",
      "The no. of time stamps for event 10 are 27\n",
      "The no. of time stamps for event 11 are 18\n",
      "The no. of time stamps for event 12 are 16\n",
      "The no. of time stamps for event 13 are 19\n",
      "The no. of time stamps for event 14 are 16\n",
      "The no. of time stamps for event 15 are 15\n",
      "The no. of time stamps for event 16 are 14\n",
      "Data for Subject 3 has been cleaned.\n",
      "The no. of time stamps for event 1 are 23\n",
      "The no. of time stamps for event 2 are 19\n",
      "The no. of time stamps for event 3 are 19\n",
      "The no. of time stamps for event 4 are 21\n",
      "The no. of time stamps for event 5 are 19\n",
      "The no. of time stamps for event 6 are 18\n",
      "The no. of time stamps for event 7 are 17\n",
      "The no. of time stamps for event 8 are 23\n",
      "The no. of time stamps for event 9 are 16\n",
      "The no. of time stamps for event 10 are 18\n",
      "The no. of time stamps for event 11 are 16\n",
      "The no. of time stamps for event 12 are 16\n",
      "The no. of time stamps for event 13 are 23\n",
      "The no. of time stamps for event 14 are 16\n",
      "The no. of time stamps for event 15 are 19\n",
      "The no. of time stamps for event 16 are 15\n",
      "Data for Subject 4 has been cleaned.\n",
      "The no. of time stamps for event 1 are 38\n",
      "The no. of time stamps for event 2 are 25\n",
      "The no. of time stamps for event 3 are 18\n",
      "The no. of time stamps for event 4 are 17\n",
      "The no. of time stamps for event 5 are 19\n",
      "The no. of time stamps for event 6 are 17\n",
      "The no. of time stamps for event 7 are 15\n",
      "The no. of time stamps for event 8 are 17\n",
      "The no. of time stamps for event 9 are 15\n",
      "The no. of time stamps for event 10 are 17\n",
      "The no. of time stamps for event 11 are 15\n",
      "The no. of time stamps for event 12 are 15\n",
      "The no. of time stamps for event 13 are 18\n",
      "The no. of time stamps for event 14 are 20\n",
      "The no. of time stamps for event 15 are 15\n",
      "The no. of time stamps for event 16 are 63\n",
      "Data for Subject 5 has been cleaned.\n",
      "The no. of time stamps for event 1 are 41\n",
      "The no. of time stamps for event 2 are 18\n",
      "The no. of time stamps for event 3 are 11\n",
      "The no. of time stamps for event 4 are 17\n",
      "The no. of time stamps for event 5 are 18\n",
      "The no. of time stamps for event 6 are 21\n",
      "The no. of time stamps for event 7 are 16\n",
      "The no. of time stamps for event 8 are 16\n",
      "The no. of time stamps for event 9 are 11\n",
      "The no. of time stamps for event 10 are 17\n",
      "The no. of time stamps for event 11 are 17\n",
      "The no. of time stamps for event 12 are 16\n",
      "The no. of time stamps for event 13 are 17\n",
      "The no. of time stamps for event 14 are 13\n",
      "The no. of time stamps for event 15 are 16\n",
      "The no. of time stamps for event 16 are 16\n",
      "Data for Subject 6 has been cleaned.\n",
      "The no. of time stamps for event 1 are 14\n",
      "The no. of time stamps for event 2 are 22\n",
      "The no. of time stamps for event 3 are 20\n",
      "The no. of time stamps for event 4 are 12\n",
      "The no. of time stamps for event 5 are 26\n",
      "The no. of time stamps for event 6 are 18\n",
      "The no. of time stamps for event 7 are 18\n",
      "The no. of time stamps for event 8 are 16\n",
      "The no. of time stamps for event 9 are 17\n",
      "The no. of time stamps for event 10 are 15\n",
      "The no. of time stamps for event 11 are 15\n",
      "The no. of time stamps for event 12 are 39\n",
      "The no. of time stamps for event 13 are 19\n",
      "The no. of time stamps for event 14 are 19\n",
      "The no. of time stamps for event 15 are 17\n",
      "The no. of time stamps for event 16 are 15\n",
      "Data for Subject 7 has been cleaned.\n",
      "The no. of time stamps for event 1 are 18\n",
      "The no. of time stamps for event 2 are 16\n",
      "The no. of time stamps for event 3 are 16\n",
      "The no. of time stamps for event 4 are 17\n",
      "The no. of time stamps for event 5 are 55\n",
      "The no. of time stamps for event 6 are 22\n",
      "The no. of time stamps for event 7 are 32\n",
      "The no. of time stamps for event 8 are 16\n",
      "The no. of time stamps for event 9 are 21\n",
      "The no. of time stamps for event 10 are 21\n",
      "The no. of time stamps for event 11 are 16\n",
      "The no. of time stamps for event 12 are 18\n",
      "The no. of time stamps for event 13 are 17\n",
      "The no. of time stamps for event 14 are 16\n",
      "The no. of time stamps for event 15 are 13\n",
      "The no. of time stamps for event 16 are 16\n",
      "Data for Subject 8 has been cleaned.\n",
      "The no. of time stamps for event 1 are 22\n",
      "The no. of time stamps for event 2 are 17\n",
      "The no. of time stamps for event 3 are 31\n",
      "The no. of time stamps for event 4 are 19\n",
      "The no. of time stamps for event 5 are 32\n",
      "The no. of time stamps for event 6 are 17\n",
      "The no. of time stamps for event 7 are 16\n",
      "The no. of time stamps for event 8 are 33\n",
      "The no. of time stamps for event 9 are 16\n",
      "The no. of time stamps for event 10 are 49\n",
      "The no. of time stamps for event 11 are 21\n",
      "The no. of time stamps for event 12 are 15\n",
      "The no. of time stamps for event 13 are 15\n",
      "The no. of time stamps for event 14 are 17\n",
      "The no. of time stamps for event 15 are 19\n",
      "The no. of time stamps for event 16 are 17\n",
      "Data for Subject 9 has been cleaned.\n",
      "The no. of time stamps for event 1 are 21\n",
      "The no. of time stamps for event 2 are 16\n",
      "The no. of time stamps for event 3 are 28\n",
      "The no. of time stamps for event 4 are 29\n",
      "The no. of time stamps for event 5 are 17\n",
      "The no. of time stamps for event 6 are 11\n",
      "The no. of time stamps for event 7 are 17\n",
      "The no. of time stamps for event 8 are 9\n",
      "The no. of time stamps for event 9 are 12\n",
      "The no. of time stamps for event 10 are 14\n",
      "The no. of time stamps for event 11 are 14\n",
      "The no. of time stamps for event 12 are 16\n",
      "The no. of time stamps for event 13 are 14\n",
      "The no. of time stamps for event 14 are 11\n",
      "The no. of time stamps for event 15 are 14\n",
      "The no. of time stamps for event 16 are 22\n",
      "Data for Subject 10 has been cleaned.\n",
      "The no. of time stamps for event 1 are 13\n",
      "The no. of time stamps for event 2 are 21\n",
      "The no. of time stamps for event 3 are 16\n",
      "The no. of time stamps for event 4 are 17\n",
      "The no. of time stamps for event 5 are 18\n",
      "The no. of time stamps for event 6 are 13\n",
      "The no. of time stamps for event 7 are 19\n",
      "The no. of time stamps for event 8 are 16\n",
      "The no. of time stamps for event 9 are 18\n",
      "The no. of time stamps for event 10 are 20\n",
      "The no. of time stamps for event 11 are 22\n",
      "The no. of time stamps for event 12 are 17\n",
      "The no. of time stamps for event 13 are 20\n",
      "The no. of time stamps for event 14 are 20\n",
      "The no. of time stamps for event 15 are 17\n",
      "The no. of time stamps for event 16 are 15\n",
      "Data for Subject 11 has been cleaned.\n",
      "The no. of time stamps for event 1 are 20\n",
      "The no. of time stamps for event 2 are 22\n",
      "The no. of time stamps for event 3 are 23\n",
      "The no. of time stamps for event 4 are 21\n",
      "The no. of time stamps for event 5 are 17\n",
      "The no. of time stamps for event 6 are 19\n",
      "The no. of time stamps for event 7 are 18\n",
      "The no. of time stamps for event 8 are 16\n",
      "The no. of time stamps for event 9 are 17\n",
      "The no. of time stamps for event 10 are 17\n",
      "The no. of time stamps for event 11 are 15\n",
      "The no. of time stamps for event 12 are 17\n",
      "The no. of time stamps for event 13 are 25\n",
      "The no. of time stamps for event 14 are 12\n",
      "The no. of time stamps for event 15 are 60\n",
      "The no. of time stamps for event 16 are 19\n",
      "Data for Subject 12 has been cleaned.\n",
      "The no. of time stamps for event 1 are 15\n",
      "The no. of time stamps for event 2 are 21\n",
      "The no. of time stamps for event 3 are 17\n",
      "The no. of time stamps for event 4 are 19\n",
      "The no. of time stamps for event 5 are 16\n",
      "The no. of time stamps for event 6 are 36\n",
      "The no. of time stamps for event 7 are 11\n",
      "The no. of time stamps for event 8 are 9\n",
      "The no. of time stamps for event 9 are 20\n",
      "The no. of time stamps for event 10 are 20\n",
      "The no. of time stamps for event 11 are 20\n",
      "The no. of time stamps for event 12 are 18\n",
      "The no. of time stamps for event 13 are 20\n",
      "The no. of time stamps for event 14 are 16\n",
      "The no. of time stamps for event 15 are 15\n",
      "The no. of time stamps for event 16 are 15\n",
      "Data for Subject 13 has been cleaned.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no. of time stamps for event 1 are 22\n",
      "The no. of time stamps for event 2 are 14\n",
      "The no. of time stamps for event 3 are 16\n",
      "The no. of time stamps for event 4 are 20\n",
      "The no. of time stamps for event 5 are 15\n",
      "The no. of time stamps for event 6 are 15\n",
      "The no. of time stamps for event 7 are 18\n",
      "The no. of time stamps for event 8 are 16\n",
      "The no. of time stamps for event 9 are 17\n",
      "The no. of time stamps for event 10 are 15\n",
      "The no. of time stamps for event 11 are 15\n",
      "The no. of time stamps for event 12 are 15\n",
      "The no. of time stamps for event 13 are 16\n",
      "The no. of time stamps for event 14 are 25\n",
      "The no. of time stamps for event 15 are 19\n",
      "The no. of time stamps for event 16 are 23\n",
      "Data for Subject 14 has been cleaned.\n",
      "The no. of time stamps for event 1 are 21\n",
      "The no. of time stamps for event 2 are 18\n",
      "The no. of time stamps for event 3 are 18\n",
      "The no. of time stamps for event 4 are 20\n",
      "The no. of time stamps for event 5 are 65\n",
      "The no. of time stamps for event 6 are 18\n",
      "The no. of time stamps for event 7 are 17\n",
      "The no. of time stamps for event 8 are 16\n",
      "The no. of time stamps for event 9 are 20\n",
      "The no. of time stamps for event 10 are 36\n",
      "The no. of time stamps for event 11 are 12\n",
      "The no. of time stamps for event 12 are 19\n",
      "The no. of time stamps for event 13 are 15\n",
      "The no. of time stamps for event 14 are 31\n",
      "The no. of time stamps for event 15 are 19\n",
      "The no. of time stamps for event 16 are 15\n",
      "Data for Subject 15 has been cleaned.\n",
      "The no. of time stamps for event 1 are 19\n",
      "The no. of time stamps for event 2 are 18\n",
      "The no. of time stamps for event 3 are 17\n",
      "The no. of time stamps for event 4 are 16\n",
      "The no. of time stamps for event 5 are 22\n",
      "The no. of time stamps for event 6 are 16\n",
      "The no. of time stamps for event 7 are 11\n",
      "The no. of time stamps for event 8 are 14\n",
      "The no. of time stamps for event 9 are 18\n",
      "The no. of time stamps for event 10 are 17\n",
      "The no. of time stamps for event 11 are 16\n",
      "The no. of time stamps for event 12 are 15\n",
      "The no. of time stamps for event 13 are 10\n",
      "The no. of time stamps for event 14 are 18\n",
      "The no. of time stamps for event 15 are 14\n",
      "The no. of time stamps for event 16 are 18\n",
      "Data for Subject 16 has been cleaned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no. of time stamps for event 1 are 23\n",
      "The no. of time stamps for event 2 are 19\n",
      "The no. of time stamps for event 3 are 17\n",
      "The no. of time stamps for event 4 are 10\n",
      "The no. of time stamps for event 5 are 16\n",
      "The no. of time stamps for event 6 are 10\n",
      "The no. of time stamps for event 7 are 31\n",
      "The no. of time stamps for event 8 are 32\n",
      "The no. of time stamps for event 9 are 16\n",
      "The no. of time stamps for event 10 are 15\n",
      "The no. of time stamps for event 11 are 14\n",
      "The no. of time stamps for event 12 are 9\n",
      "The no. of time stamps for event 13 are 14\n",
      "The no. of time stamps for event 14 are 13\n",
      "The no. of time stamps for event 15 are 12\n",
      "The no. of time stamps for event 16 are 14\n",
      "Data for Subject 17 has been cleaned.\n",
      "The no. of time stamps for event 1 are 34\n",
      "The no. of time stamps for event 2 are 22\n",
      "The no. of time stamps for event 3 are 25\n",
      "The no. of time stamps for event 4 are 22\n",
      "The no. of time stamps for event 5 are 19\n",
      "The no. of time stamps for event 6 are 27\n",
      "The no. of time stamps for event 7 are 18\n",
      "The no. of time stamps for event 8 are 19\n",
      "The no. of time stamps for event 9 are 22\n",
      "The no. of time stamps for event 10 are 18\n",
      "The no. of time stamps for event 11 are 22\n",
      "The no. of time stamps for event 12 are 15\n",
      "The no. of time stamps for event 13 are 18\n",
      "The no. of time stamps for event 14 are 18\n",
      "The no. of time stamps for event 15 are 19\n",
      "The no. of time stamps for event 16 are 19\n",
      "Data for Subject 18 has been cleaned.\n",
      "The no. of time stamps for event 1 are 23\n",
      "The no. of time stamps for event 2 are 11\n",
      "The no. of time stamps for event 3 are 10\n",
      "The no. of time stamps for event 4 are 20\n",
      "The no. of time stamps for event 5 are 26\n",
      "The no. of time stamps for event 6 are 21\n",
      "The no. of time stamps for event 7 are 17\n",
      "The no. of time stamps for event 8 are 17\n",
      "The no. of time stamps for event 9 are 19\n",
      "The no. of time stamps for event 10 are 18\n",
      "The no. of time stamps for event 11 are 55\n",
      "The no. of time stamps for event 12 are 19\n",
      "The no. of time stamps for event 13 are 19\n",
      "The no. of time stamps for event 14 are 16\n",
      "The no. of time stamps for event 15 are 14\n",
      "The no. of time stamps for event 16 are 18\n",
      "Data for Subject 19 has been cleaned.\n",
      "The no. of time stamps for event 1 are 21\n",
      "The no. of time stamps for event 2 are 22\n",
      "The no. of time stamps for event 3 are 37\n",
      "The no. of time stamps for event 4 are 20\n",
      "The no. of time stamps for event 5 are 19\n",
      "The no. of time stamps for event 6 are 18\n",
      "The no. of time stamps for event 7 are 19\n",
      "The no. of time stamps for event 8 are 18\n",
      "The no. of time stamps for event 9 are 16\n",
      "The no. of time stamps for event 10 are 17\n",
      "The no. of time stamps for event 11 are 15\n",
      "The no. of time stamps for event 12 are 16\n",
      "The no. of time stamps for event 13 are 19\n",
      "The no. of time stamps for event 14 are 20\n",
      "The no. of time stamps for event 15 are 20\n",
      "The no. of time stamps for event 16 are 22\n",
      "Data for Subject 20 has been cleaned.\n",
      "The no. of time stamps for event 1 are 52\n",
      "The no. of time stamps for event 2 are 43\n",
      "The no. of time stamps for event 3 are 19\n",
      "The no. of time stamps for event 4 are 20\n",
      "The no. of time stamps for event 5 are 28\n",
      "The no. of time stamps for event 6 are 21\n",
      "The no. of time stamps for event 7 are 22\n",
      "The no. of time stamps for event 8 are 32\n",
      "The no. of time stamps for event 9 are 20\n",
      "The no. of time stamps for event 10 are 34\n",
      "The no. of time stamps for event 11 are 19\n",
      "The no. of time stamps for event 12 are 19\n",
      "The no. of time stamps for event 13 are 17\n",
      "The no. of time stamps for event 14 are 16\n",
      "The no. of time stamps for event 15 are 18\n",
      "The no. of time stamps for event 16 are 19\n",
      "Data for Subject 21 has been cleaned.\n",
      "The no. of time stamps for event 1 are 67\n",
      "The no. of time stamps for event 2 are 40\n",
      "The no. of time stamps for event 3 are 51\n",
      "The no. of time stamps for event 4 are 37\n",
      "The no. of time stamps for event 5 are 21\n",
      "The no. of time stamps for event 6 are 21\n",
      "The no. of time stamps for event 7 are 12\n",
      "The no. of time stamps for event 8 are 20\n",
      "The no. of time stamps for event 9 are 19\n",
      "The no. of time stamps for event 10 are 21\n",
      "The no. of time stamps for event 11 are 21\n",
      "The no. of time stamps for event 12 are 18\n",
      "The no. of time stamps for event 13 are 14\n",
      "The no. of time stamps for event 14 are 21\n",
      "The no. of time stamps for event 15 are 19\n",
      "The no. of time stamps for event 16 are 21\n",
      "Data for Subject 22 has been cleaned.\n",
      "The no. of time stamps for event 1 are 13\n",
      "The no. of time stamps for event 2 are 21\n",
      "The no. of time stamps for event 3 are 18\n",
      "The no. of time stamps for event 4 are 25\n",
      "The no. of time stamps for event 5 are 19\n",
      "The no. of time stamps for event 6 are 17\n",
      "The no. of time stamps for event 7 are 18\n",
      "The no. of time stamps for event 8 are 18\n",
      "The no. of time stamps for event 9 are 21\n",
      "The no. of time stamps for event 10 are 18\n",
      "The no. of time stamps for event 11 are 16\n",
      "The no. of time stamps for event 12 are 21\n",
      "The no. of time stamps for event 13 are 21\n",
      "The no. of time stamps for event 14 are 18\n",
      "The no. of time stamps for event 15 are 17\n",
      "The no. of time stamps for event 16 are 15\n",
      "Data for Subject 23 has been cleaned.\n",
      "The no. of time stamps for event 1 are 24\n",
      "The no. of time stamps for event 2 are 21\n",
      "The no. of time stamps for event 3 are 19\n",
      "The no. of time stamps for event 4 are 17\n",
      "The no. of time stamps for event 5 are 15\n",
      "The no. of time stamps for event 6 are 20\n",
      "The no. of time stamps for event 7 are 13\n",
      "The no. of time stamps for event 8 are 17\n",
      "The no. of time stamps for event 9 are 19\n",
      "The no. of time stamps for event 10 are 12\n",
      "The no. of time stamps for event 11 are 19\n",
      "The no. of time stamps for event 12 are 18\n",
      "The no. of time stamps for event 13 are 20\n",
      "The no. of time stamps for event 14 are 23\n",
      "The no. of time stamps for event 15 are 25\n",
      "The no. of time stamps for event 16 are 28\n",
      "Data for Subject 24 has been cleaned.\n",
      "The no. of time stamps for event 1 are 26\n",
      "The no. of time stamps for event 2 are 25\n",
      "The no. of time stamps for event 3 are 19\n",
      "The no. of time stamps for event 4 are 11\n",
      "The no. of time stamps for event 5 are 19\n",
      "The no. of time stamps for event 6 are 45\n",
      "The no. of time stamps for event 7 are 17\n",
      "The no. of time stamps for event 8 are 11\n",
      "The no. of time stamps for event 9 are 13\n",
      "The no. of time stamps for event 10 are 17\n",
      "The no. of time stamps for event 11 are 17\n",
      "The no. of time stamps for event 12 are 18\n",
      "The no. of time stamps for event 13 are 18\n",
      "The no. of time stamps for event 14 are 18\n",
      "The no. of time stamps for event 15 are 11\n",
      "The no. of time stamps for event 16 are 16\n",
      "Data for Subject 25 has been cleaned.\n",
      "The no. of time stamps for event 1 are 34\n",
      "The no. of time stamps for event 2 are 22\n",
      "The no. of time stamps for event 3 are 22\n",
      "The no. of time stamps for event 4 are 13\n",
      "The no. of time stamps for event 5 are 18\n",
      "The no. of time stamps for event 6 are 53\n",
      "The no. of time stamps for event 7 are 19\n",
      "The no. of time stamps for event 8 are 19\n",
      "The no. of time stamps for event 9 are 32\n",
      "The no. of time stamps for event 10 are 16\n",
      "The no. of time stamps for event 11 are 53\n",
      "The no. of time stamps for event 12 are 17\n",
      "The no. of time stamps for event 13 are 23\n",
      "The no. of time stamps for event 14 are 19\n",
      "The no. of time stamps for event 15 are 17\n",
      "The no. of time stamps for event 16 are 17\n",
      "Data for Subject 26 has been cleaned.\n",
      "The no. of time stamps for event 1 are 26\n",
      "The no. of time stamps for event 2 are 46\n",
      "The no. of time stamps for event 3 are 22\n",
      "The no. of time stamps for event 4 are 21\n",
      "The no. of time stamps for event 5 are 20\n",
      "The no. of time stamps for event 6 are 16\n",
      "The no. of time stamps for event 7 are 15\n",
      "The no. of time stamps for event 8 are 17\n",
      "The no. of time stamps for event 9 are 10\n",
      "The no. of time stamps for event 10 are 19\n",
      "The no. of time stamps for event 11 are 24\n",
      "The no. of time stamps for event 12 are 21\n",
      "The no. of time stamps for event 13 are 16\n",
      "The no. of time stamps for event 14 are 15\n",
      "The no. of time stamps for event 15 are 15\n",
      "The no. of time stamps for event 16 are 17\n",
      "Data for Subject 27 has been cleaned.\n",
      "The no. of time stamps for event 1 are 17\n",
      "The no. of time stamps for event 2 are 23\n",
      "The no. of time stamps for event 3 are 34\n",
      "The no. of time stamps for event 4 are 19\n",
      "The no. of time stamps for event 5 are 16\n",
      "The no. of time stamps for event 6 are 15\n",
      "The no. of time stamps for event 7 are 19\n",
      "The no. of time stamps for event 8 are 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no. of time stamps for event 9 are 16\n",
      "The no. of time stamps for event 10 are 18\n",
      "The no. of time stamps for event 11 are 17\n",
      "The no. of time stamps for event 12 are 14\n",
      "The no. of time stamps for event 13 are 18\n",
      "The no. of time stamps for event 14 are 19\n",
      "The no. of time stamps for event 15 are 25\n",
      "The no. of time stamps for event 16 are 17\n",
      "Data for Subject 28 has been cleaned.\n",
      "The no. of time stamps for event 1 are 52\n",
      "The no. of time stamps for event 2 are 40\n",
      "The no. of time stamps for event 3 are 22\n",
      "The no. of time stamps for event 4 are 21\n",
      "The no. of time stamps for event 5 are 17\n",
      "The no. of time stamps for event 6 are 26\n",
      "The no. of time stamps for event 7 are 22\n",
      "The no. of time stamps for event 8 are 25\n",
      "The no. of time stamps for event 9 are 18\n",
      "The no. of time stamps for event 10 are 25\n",
      "The no. of time stamps for event 11 are 18\n",
      "The no. of time stamps for event 12 are 10\n",
      "The no. of time stamps for event 13 are 21\n",
      "The no. of time stamps for event 14 are 16\n",
      "The no. of time stamps for event 15 are 17\n",
      "The no. of time stamps for event 16 are 17\n",
      "Data for Subject 29 has been cleaned.\n",
      "The no. of time stamps for event 1 are 58\n",
      "The no. of time stamps for event 2 are 35\n",
      "The no. of time stamps for event 3 are 36\n",
      "The no. of time stamps for event 4 are 38\n",
      "The no. of time stamps for event 5 are 17\n",
      "The no. of time stamps for event 6 are 19\n",
      "The no. of time stamps for event 7 are 20\n",
      "The no. of time stamps for event 8 are 17\n",
      "The no. of time stamps for event 9 are 16\n",
      "The no. of time stamps for event 10 are 23\n",
      "The no. of time stamps for event 11 are 19\n",
      "The no. of time stamps for event 12 are 16\n",
      "The no. of time stamps for event 13 are 18\n",
      "The no. of time stamps for event 14 are 18\n",
      "The no. of time stamps for event 15 are 16\n",
      "The no. of time stamps for event 16 are 22\n",
      "The no. of time stamps for event 17 are 0\n",
      "Data for Subject 30 has been cleaned.\n",
      "The no. of time stamps for event 1 are 19\n",
      "The no. of time stamps for event 2 are 12\n",
      "The no. of time stamps for event 3 are 18\n",
      "The no. of time stamps for event 4 are 18\n",
      "The no. of time stamps for event 5 are 55\n",
      "The no. of time stamps for event 6 are 17\n",
      "The no. of time stamps for event 7 are 17\n",
      "The no. of time stamps for event 8 are 17\n",
      "The no. of time stamps for event 9 are 39\n",
      "The no. of time stamps for event 10 are 15\n",
      "The no. of time stamps for event 11 are 17\n",
      "The no. of time stamps for event 12 are 19\n",
      "The no. of time stamps for event 13 are 15\n",
      "The no. of time stamps for event 14 are 17\n",
      "The no. of time stamps for event 15 are 13\n",
      "The no. of time stamps for event 16 are 18\n",
      "Data for Subject 31 has been cleaned.\n",
      "The no. of time stamps for event 1 are 21\n",
      "The no. of time stamps for event 2 are 25\n",
      "The no. of time stamps for event 3 are 21\n",
      "The no. of time stamps for event 4 are 17\n",
      "The no. of time stamps for event 5 are 28\n",
      "The no. of time stamps for event 6 are 22\n",
      "The no. of time stamps for event 7 are 37\n",
      "The no. of time stamps for event 8 are 17\n",
      "The no. of time stamps for event 9 are 15\n",
      "The no. of time stamps for event 10 are 19\n",
      "The no. of time stamps for event 11 are 17\n",
      "The no. of time stamps for event 12 are 16\n",
      "The no. of time stamps for event 13 are 27\n",
      "The no. of time stamps for event 14 are 20\n",
      "The no. of time stamps for event 15 are 29\n",
      "Data for Subject 32 has been cleaned.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "filepaths = pd.read_excel('/Users/RSM/Desktop/cvs_data/filepaths.xlsx', header = None)\n",
    "\n",
    "input_data = pd.DataFrame()\n",
    "output_data = pd.DataFrame()\n",
    "splitVector = pd.DataFrame()\n",
    "    \n",
    "\n",
    "for i in range (len(filepaths)):\n",
    "    filepath = filepaths[0][i]\n",
    "    data = pd.read_excel(filepath, sheet_name = 'Data')\n",
    "    scen_data = pd.read_excel(filepath, sheet_name = 'SUMMARY')\n",
    "    cleaned_data, dataSplitVector, output = function1(data, scen_data)\n",
    "    dataSplitVector = pd.DataFrame(dataSplitVector)\n",
    "    input_data = input_data.append(cleaned_data, ignore_index = True)\n",
    "    output_data = output_data.append(output, ignore_index = True)\n",
    "    splitVector = splitVector.append(dataSplitVector, ignore_index = True)\n",
    "    print(\"Data for Subject {} has been cleaned.\".format(i+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = input_data.drop(['crash', 'trans_gear', 'trans gear', 'warning'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_copy = output_data[:]\n",
    "#output_copy = output_copy.drop(splitVector[splitVector[0] == 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_copy.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([480], dtype='int64')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitVector[splitVector[0]==0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "416/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.to_excel('cleaned_data_version_01.xlsx')\n",
    "output_data.to_excel('output_data_version_01.xlsx')\n",
    "splitVector.to_excel('data_split_version_01.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling the LSTM\n",
    "\n",
    "This part of the code will do some further preprocessing of the data to make it ready for the LSTM. Follwoing which, an LSTM model will be built, trained and tested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Defining the LSTM model as a class. The model we will train later will be the instance of this class.\n",
    "\n",
    "class collisionClassifier(nn.Module):\n",
    "    def __init__(self, no_of_features, features_to_hidden, features_in_hidden, max_sequence_length, no_of_layers = 1):\n",
    "        super().__init__()\n",
    "        self.features_in_hidden = features_in_hidden\n",
    "        self.features_to_hidden = features_to_hidden\n",
    "        self.no_of_layers = no_of_layers\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.linear_layer_1 = nn.Linear(no_of_features, features_to_hidden)\n",
    "        self.lstm_cell = nn.LSTM(features_to_hidden, features_in_hidden, no_of_layers)\n",
    "        self.dropout_layer = nn.Dropout(0.2)\n",
    "        self.relu_layer = nn.ReLU()\n",
    "        self.linear_layer_2 = nn.Linear(features_in_hidden,2)\n",
    "        self.smc = nn.Softmax()\n",
    "        \n",
    "    def __init__hidden(self, max_sequence_length):\n",
    "        hidden = torch.rand(1, max_sequence_length, self.features_in_hidden)\n",
    "        return Variable(hidden, requires_grad = True)\n",
    "        \n",
    "    def __init__cellstate(self, max_sequence_length):\n",
    "        cellstate = torch.rand(1,max_sequence_length , self.features_in_hidden)\n",
    "        return Variable(cellstate, requires_grad = True)\n",
    "    \n",
    "    def forward_pass(self, input_data,sequence_length):\n",
    "        output = self.linear_layer_1(input_data)\n",
    "        output, _ = self.lstm_cell(output)\n",
    "        output = self.relu_layer(output[0,int(sequence_length-1),:])\n",
    "        output = self.linear_layer_2(output)\n",
    "        output = self.smc(output)     #hidden[:,(sequence_length-1),:])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_multiplier_and_shaper(driving_data, output_data, data_split_vector, multiplier):\n",
    "    driving_data_large = driving_data\n",
    "    output_data_large = output_data\n",
    "    data_split_vector_large = data_split_vector\n",
    "    for i in range (0,multiplier):\n",
    "        driving_data_large = np.append(driving_data_large, driving_data)\n",
    "        output_data_large = np.append(output_data_large,output_data)\n",
    "        data_split_vector_large = np.append(data_split_vector_large, data_split_vector)\n",
    "    x = 1*driving_data.shape[0]\n",
    "    driving_data_large = driving_data_large.reshape(x,13)\n",
    "    a = len(data_split_vector)\n",
    "    b = len(data_split_vector_large)\n",
    "    for i in range(a,b):\n",
    "        driving_data_large[a,:] = driving_data_large[a,:] + \\\n",
    "        np.random.normal(loc = 0, scale = 1, size = (1,driving_data.shape[1]))\n",
    "\n",
    "    return data_scaler(driving_data_large, data_split_vector_large) , output_data_large, data_split_vector_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_scaler(driving_data, data_split_vector):\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    no_of_data_points = driving_data.shape[0]\n",
    "    no_of_columns = driving_data.shape[1]\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range = (0,1))\n",
    "    scaledData = scaler.fit_transform(driving_data)\n",
    "    scaledData = scaledData.reshape([1, no_of_data_points, no_of_columns])\n",
    "    \n",
    "    return paddingMethod(scaledData, data_split_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paddingMethod(scenario_data, data_split_vector):\n",
    "    scenario_tensor = torch.zeros((len(data_split_vector),max(max(data_split_vector)),scenario_data.shape[2])).float()\n",
    "\n",
    "    j = 0    \n",
    "    for idx, scen_length in enumerate(data_split_vector):\n",
    "        for i in range (max(scen_length)):\n",
    "            scenario_tensor[idx,i,:] = torch.FloatTensor(scenario_data[0,j+i,:])\n",
    "        j += max(scen_length)\n",
    "        \n",
    "    print(\"The input data shape is {}\".format(scenario_tensor.shape))\n",
    "    \n",
    "    return scenario_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_error(linear_output, target):\n",
    "    a = [1,1]\n",
    "    a = torch.Tensor(a)\n",
    "    loss = nn.CrossEntropyLoss(weight = a)\n",
    "    error = loss(linear_output,target)\n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_split(k_folds, input_data, output_data, data_split_vector, k): # k is the fold number\n",
    "    #k_folds = 8\n",
    "    independent_events = input_data.size()[0]\n",
    "    data_per_fold = int(independent_events/k_folds)\n",
    "    train_events = (k_folds - 1)*data_per_fold    #int(independent_events*0.8)\n",
    "    input_test_data = torch.zeros((data_per_fold,input_data.size()[1],input_data.size()[2]))\n",
    "    input_train_data = torch.zeros((data_per_fold*(k_folds-1),input_data.size()[1],input_data.size()[2]))\n",
    "    input_train_target = torch.zeros((data_per_fold*(k_folds - 1)))\n",
    "    input_train_target = input_train_target.type(torch.LongTensor)\n",
    "    train_datasplit = np.zeros([1,data_per_fold*(k_folds - 1)])\n",
    "    test_datasplit = np.zeros([1, data_per_fold])\n",
    "    \n",
    "    counter = 0 \n",
    "    for l in range (k_folds):\n",
    "        if l == k:\n",
    "            input_test_data = input_data[l*data_per_fold:(l+1)*data_per_fold,:,:]\n",
    "            test_target = output_data[l*data_per_fold:(l+1)*data_per_fold,0]\n",
    "            test_datasplit = data_split_vector[l*data_per_fold:(l+1)*data_per_fold,0]\n",
    "        else:\n",
    "            input_train_data[counter*data_per_fold:(counter+1)*data_per_fold,:,:] = input_data[l*data_per_fold:\\\n",
    "                                                                                               (l+1)*data_per_fold,:,:]\n",
    "            input_train_target[counter*data_per_fold:(counter+1)*data_per_fold]= output_data[l*data_per_fold:(l+1)*data_per_fold,0] \n",
    "            train_datasplit[0,counter*data_per_fold:(counter+1)*data_per_fold] = data_split_vector[l*data_per_fold:(l+1)*data_per_fold,0]\n",
    "            counter += 1\n",
    "            \n",
    "    return input_train_data, input_train_target, input_test_data, test_target, train_events, train_datasplit, test_datasplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init(input_train_data, input_train_target, no_of_batches, data_split_vector, train_datasplit, epoch):\n",
    "    \n",
    "    collision_predictor = collisionClassifier(no_of_features = input_train_data.size()[2],features_to_hidden = 10, \\\n",
    "                                          features_in_hidden = 2, max_sequence_length = max(data_split_vector))\n",
    "    \n",
    "    batch_size = int(input_train_data.size()[0]/no_of_batches)\n",
    "    optimizer = torch.optim.Adam(collision_predictor.parameters(), lr=0.001)\n",
    "    \n",
    "    return model_trainer(input_train_data, input_train_target, no_of_batches, data_split_vector,\\\n",
    "                         train_datasplit, batch_size, optimizer, collision_predictor, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_trainer(input_train_data, input_train_target, no_of_batches, data_split_vector,\\\n",
    "                         train_datasplit, batch_size, optimizer, collision_predictor, epoch):\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        for j in range(no_of_batches):\n",
    "            pred_tensor = torch.zeros(batch_size,2)\n",
    "            target = torch.LongTensor(input_train_target)\n",
    "            target_tensor = target[j*batch_size:(j+1)*batch_size] \n",
    "            for k in range (batch_size):\n",
    "                event_no = (batch_size*j)+k\n",
    "                prediction = collision_predictor.forward_pass(input_train_data[event_no,:,:].unsqueeze(0),\\\n",
    "                                                                      train_datasplit[0,event_no])\n",
    "                pred_tensor[k] = prediction\n",
    "        \n",
    "            error = avg_error(pred_tensor,target_tensor)\n",
    "            collision_predictor.zero_grad()\n",
    "            error.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(\"The error for epoch {} was: {}\".format((i+1),error))\n",
    "            \n",
    "    return collision_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(input_test_data, test_target, collision_predictor, test_datasplit):\n",
    "    \n",
    "    test_target = np.array(test_target)\n",
    "    test_predictions = np.zeros(test_target.shape)\n",
    "    event_no = 0\n",
    "    for i in range(0,input_test_data.shape[0]):\n",
    "        test_output = collision_predictor.forward_pass(input_test_data[i,:,:].unsqueeze(0), \\\n",
    "                                                                test_datasplit[event_no])\n",
    "        if test_output[0] < test_output[1]:\n",
    "            test_predictions[i] = 1\n",
    "        else :\n",
    "            test_predictions[i] = 0\n",
    "        event_no += 1\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "    for i in range(0, input_test_data.shape[0]):\n",
    "        if ((test_predictions[i] == test_target[i]) & (test_predictions[i] == 1)):\n",
    "            tp += 1\n",
    "        if ((test_predictions[i] == test_target[i]) & (test_predictions[i] == 0)):\n",
    "            tn += 1\n",
    "        elif((test_predictions[i] != test_target[i]) & (test_predictions[i] == 1)):\n",
    "            fp += 1\n",
    "        elif((test_predictions[i] != test_target[i]) & (test_predictions[i] == 0)):\n",
    "            fn += 1\n",
    "    return tp, fp, fn, tn, test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_function(driving_data, output_data,data_split_vector,multiplier = 0, k_folds = 8,no_of_batches = 4, epoch = 20):\n",
    "\n",
    "    input_data, output, data_split_vector = data_multiplier_and_shaper(driving_data, output_data,data_split_vector,multiplier)\n",
    "    print(\"There are {} inputs to the LSTM. How many folds do you want for your cross-validation, default being 8?\".format(input_data.shape[0]))\n",
    "    k_folds = input()\n",
    "    k_folds = int(k_folds)\n",
    "    print(\"What is the number of batches you desire the training data be split into? Default is set at 4\")\n",
    "    no_of_batches = input()\n",
    "    no_of_batches = int(no_of_batches)\n",
    "    print(\"What is the number of epochs for which the training should be carried out? Default is set at 20\")\n",
    "    epoch = input()\n",
    "    epoch = int(epoch)\n",
    "    output_data = torch.LongTensor(output_data)\n",
    "    true_positive  = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    true_negative = 0\n",
    "    for k in range(k_folds):\n",
    "        input_train_data, input_train_target, input_test_data, test_target,train_events, \\\n",
    "        train_datasplit, test_datasplit = test_train_split(k_folds, input_data, output_data, data_split_vector, k)\n",
    "        collision_predictor = model_init(input_train_data, input_train_target, no_of_batches, data_split_vector, train_datasplit, epoch)\n",
    "        tp, fp, fn, tn, test_predictions = test(input_test_data, test_target, collision_predictor, test_datasplit)\n",
    "        true_positive  += tp\n",
    "        false_positive += fp\n",
    "        false_negative += fn\n",
    "        true_negative  += tn\n",
    "\n",
    "    #confusion_matrix = pd.DataFrame(np.array([true_positive,true_negative],[false_positive, false_negative]),columns = ['Positive (Collision)','Negative (No Collision)'], index = ['true','false'])\n",
    "    \n",
    "    return true_positive,true_negative,false_positive, false_negative, test_predictions\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the input driving data is:(10258, 13)The shape of the output data is: (512, 1)The shape of the data split vector is: (512, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# importing the time series input data\n",
    "\n",
    "filepath_main_data = \"/Users/RSM/cleaned_data_version_01.xlsx\"\n",
    "driving_data = pd.read_excel(filepath_main_data)\n",
    "driving_data = driving_data.values\n",
    "\n",
    "# importing the collision outcome for the corresponding input data\n",
    "\n",
    "filepath_output = \"/Users/RSM/output_data_version_01.xlsx\"\n",
    "output_data = pd.read_excel(filepath_output)\n",
    "output_data = output_data.values\n",
    "\n",
    "# importing the data split vector which stores the length of each time series data\n",
    "\n",
    "filepath_data_split = \"/Users/RSM/data_split_version_01.xlsx\"\n",
    "data_split_vector = pd.read_excel(filepath_data_split)\n",
    "data_split_vector = data_split_vector.values\n",
    "\n",
    "print(\"The shape of the input driving data is:{}\\\n",
    "The shape of the output data is: {}\\\n",
    "The shape of the data split vector is: {}\".format(driving_data.shape, output_data.shape, data_split_vector.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input data shape is torch.Size([512, 67, 13])\n",
      "There are 512 inputs to the LSTM. How many folds do you want for your cross-validation, default being 8?\n",
      "8\n",
      "What is the number of batches you desire the training data be split into? Default is set at 4\n",
      "4\n",
      "What is the number of epochs for which the training should be carried out? Default is set at 20\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RSM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error for epoch 1 was: 0.5995200872421265\n",
      "The error for epoch 2 was: 0.5989611744880676\n",
      "The error for epoch 3 was: 0.5984047055244446\n",
      "The error for epoch 1 was: 0.7172980904579163\n",
      "The error for epoch 2 was: 0.7161141633987427\n",
      "The error for epoch 3 was: 0.7149358987808228\n",
      "The error for epoch 1 was: 0.620996356010437\n",
      "The error for epoch 2 was: 0.6202690005302429\n",
      "The error for epoch 3 was: 0.6195478439331055\n",
      "The error for epoch 1 was: 0.5895795226097107\n",
      "The error for epoch 2 was: 0.5890313386917114\n",
      "The error for epoch 3 was: 0.5884881019592285\n",
      "The error for epoch 1 was: 0.7757959365844727\n",
      "The error for epoch 2 was: 0.7739117741584778\n",
      "The error for epoch 3 was: 0.7721189260482788\n",
      "The error for epoch 1 was: 0.6337165832519531\n",
      "The error for epoch 2 was: 0.632579505443573\n",
      "The error for epoch 3 was: 0.6314259171485901\n",
      "The error for epoch 1 was: 0.6439838409423828\n",
      "The error for epoch 2 was: 0.6410676836967468\n",
      "The error for epoch 3 was: 0.6385313868522644\n",
      "The error for epoch 1 was: 0.6472273468971252\n",
      "The error for epoch 2 was: 0.6432546973228455\n",
      "The error for epoch 3 was: 0.6396271586418152\n"
     ]
    }
   ],
   "source": [
    "\n",
    "true_positive,true_negative,false_positive, false_negative, test_predictions = main_function(driving_data, output_data,data_split_vector,multiplier = 0, k_folds = 8,no_of_batches = 4, epoch = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positive: 30 true negative: 271 false positive: 98 false negative: 113\n"
     ]
    }
   ],
   "source": [
    "print(\"true positive: {} \\\n",
    "true negative: {} \\\n",
    "false positive: {} \\\n",
    "false negative: {}\".format(true_positive,true_negative,false_positive, false_negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.587890625\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: {}\".format((true_positive + true_negative)/(true_positive + true_negative+ false_positive + false_negative)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# warrning parameters, scenario (cross-section and stratight), warning reliability, timing and type \n",
    "# gaussian error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
