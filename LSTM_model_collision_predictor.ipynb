{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling LSTM Network to Predict Collision \n",
    "\n",
    "We first create the LSTM model that will take as its input time series data from the CVS experiment. This data contains driver response for every subject and every scenario. The data we will feed the LSTM will contain driver response from 3 seconds prior to the warning and till the time the driver reacts. We will use this data to train the model to predict whether collision takes place. As the time series data for every driver-scenario combination will be of a different length, we will need to pad the data to make sure the input to the LSTM is of the same size.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "\n",
    "We will first model the LSTM network which will be fed into the softmax layer for a classification output. The LSTM layer will be fed the driving data which will be of the shape - sequence length X no_of_features. This data will be passed in batches of size batch_size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Defining the LSTM model as a class. The model we will train later will be the instance of this class.\n",
    "\n",
    "class collisionClassifier(nn.Module):\n",
    "    def __init__(self, no_of_features, features_in_hidden, output_features, max_sequence_length, no_of_layers = 1):\n",
    "        self.features_in_hidden = features_in_hidden\n",
    "        self.no_of_layers = no_of_layers\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.lstm_cell = nn.LSTM(no_of_features, features_in_hidden, bias = True)\n",
    "        self.linear_block = nn.Linear(features_in_hidden, output_features)\n",
    "        self.smc = nn.Softmax(dim = 1)\n",
    "    def __init__hidden(self, max_sequence_length):\n",
    "        hidden = torch.zeros(1, max_sequence_length, self.hidden_size)\n",
    "        return Variable(hidden)\n",
    "        \n",
    "    def __init__cellstate(self, max_sequence_length):\n",
    "        cellstate = torch.zeros(1, max_sequence_length, self.hidden_size)\n",
    "        return Variable(cellstate)\n",
    "    \n",
    "    def forward_pass(self, input_data, max_sequence_length,sequence_length):\n",
    "        hidden = self.__init__hidden(max_sequence_length)\n",
    "        cellstate = self.__init__cellstate(max_sequence_length)\n",
    "        output, (hidden,cellstate) = self.lstm_cell(input_data, (hidden, cellstate))\n",
    "        output = self.linear_block(hidden[:,(sequence_length-1)])\n",
    "        output = self.smc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will import the data from the excel sheet and scale it. Once the scaling is done, we will split the different scenario data and pad them to make all sequences of equal length.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "filepath_features = \"####################\"\n",
    "driving_data = pd.read_excel(filepath_features)\n",
    "driving_data = driving_data.values\n",
    "\n",
    "filepath_output = \"####################\"\n",
    "output_data = pd.read_excel(filepath_output)\n",
    "output_data = output_data.values\n",
    "\n",
    "no_of_data_points = driving_data.shape[0]\n",
    "no_of_columns = driving_data.shape[1]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "scaledData = scaler.fit_transform(driving_data)\n",
    "scaledData = scaledData.reshape([1, no_of_data_points, no_of_columns])\n",
    "\n",
    "data_split_vector = [#############################################]\n",
    "\n",
    "def paddingMethod(scenario_data, data_split_vector):\n",
    "    scenario_tensor = torch.zeros((len(data_split_vector),max(data_split_vector),scenario_data.shape[2])).float()\n",
    "    j = 0\n",
    "    for idx, scen_length in enumerate(data_split_vector):\n",
    "        for i in range (scen_length):\n",
    "            scenario_tensor[idx,i,:] = torch.FloatTensor(scenario_data[0,j+i,:])\n",
    "        j += scen_length\n",
    "    return scenario_tensor\n",
    "\n",
    "input_data = paddingMethod(scaledData, data_split_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "\n",
    "Now, we will split the data into training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_events = input_data.size[0]\n",
    "train_events = independent_events % 8\n",
    "input_training_data = input_data[0:(train_events+1),:,:]\n",
    "input_test_data = input_data[(training_events+1):independent_events, : ,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/markdown"
   },
   "source": [
    "## Step 4\n",
    "\n",
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the model\n",
    "\n",
    "collision_predictor = collisionClassifier(no_of_features = input_data.size[2],features_in_hidden = 3,\\\n",
    "                                          output_size = 2, max_sequence_length = max(data_split_vector))\n",
    "no_of_batches = ##############################\n",
    "batch_size =##################################\n",
    "\n",
    "def avg_error(linear_output, target):\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    error = loss(linear_output,target)\n",
    "    return error\n",
    "\n",
    "for j in range (0,(no_of_batches - 1)):\n",
    "    pred_tensor = torch.zeros(batch_size,2)\n",
    "    target_tensor =  # Need to create a tensor of the target data \n",
    "    for i in range (0,(batch_size - 1)):\n",
    "        event_no = (batch_size*j)+i\n",
    "        prediction = collision_predictor.forward(input_training_data[even_no,:,:], max(data_split_vector),\\\n",
    "                                                 data_split_vector[event_no])\n",
    "        pred_tensor[i] = prediction\n",
    "        target_tensor[i]= ###########################################\n",
    "    error = avg_error(pred_tensor,target_tensor)\n",
    "    collision_predictor.zero_grad()\n",
    "    error.backward()\n",
    "    optimizer = torch.optim.Adam(collision_predictor.parameters(), lr=0.001)\n",
    "    optimizer.step()   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5\n",
    "\n",
    "Testing the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The objective of testing is to test the accuracy of the model in predicting whther collision takes place or not\n",
    "# For this we need to first define the test data and the corresponding target data. This can then be fed into \n",
    "# forward function of the collisionClassifier class. This will generate a prediction which will be in the form \n",
    "# of a 1X2 tensor which can be hot coded to get as an output whether the collision will take place or not.\n",
    "\n",
    "# input_test_data stores the test input as a tensor  \n",
    "test_target = #####################################\n",
    "test_predictions = np.zeros(test_target.shape[0])\n",
    "event_no = #########################################\n",
    "for i in range(0,input_test_data.shape(0)):\n",
    "    output = collision_predictor.forward(input_tesst_data[i,:,:], max(data_split_vector), data_split_vector[event_no])\n",
    "    if output[0,0] < output[0,1]:\n",
    "        test_predictions[i] = 0\n",
    "    else :\n",
    "        test_predictions[i] = 1\n",
    "\n",
    "# Testing the accuracy of model predictions on thetest data set\n",
    "\n",
    "for i in range(0, input_test_data.shape[0]):\n",
    "    if test_predictions[i] == test_target[i]:\n",
    "        no_of_correct_predictions += 1\n",
    "    else:\n",
    "        no_of_wrong_predictions += 1\n",
    "\n",
    "model_accuracy = no_of_correct_predictions/(no_of_correct_predictions+ no_of_wrong_predictions)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
